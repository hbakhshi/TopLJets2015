// Class: ReadBDT_VBF0HighVPtHighMJJ
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : BDT::BDT_VBF0HighVPtHighMJJ
TMVA Release   : 4.2.1         [262657]
ROOT Release   : 6.10/09       [395785]
Creator        : ajafari
Date           : Fri Jan 18 15:07:20 2019
Host           : Linux cmsbuild49.cern.ch 2.6.32-696.10.2.el6.x86_64 #1 SMP Thu Sep 14 16:35:02 CEST 2017 x86_64 x86_64 x86_64 GNU/Linux
Dir            : /afs/cern.ch/work/a/ajafari/Vjj/CMSSW_9_4_2/src/TopLJets2015/TopAnalysis/macro
Training events: 21675
Analysis type  : [Classification]


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
V: "False" [Verbose output (short form of "VerbosityLevel" below - overrides the latter one)]
H: "False" [Print method-specific help message]
CreateMVAPdfs: "True" [Create PDFs for classifier outputs (signal and background)]
nCuts: "0" [Number of grid points in variable range used in finding optimal cut in node splitting]
BoostType: "AdaBoost" [Boosting type for the trees in the forest (note: AdaCost is still experimental)]
NegWeightTreatment: "inverseboostnegweights" [How to treat events with negative weights in the BDT training (particular the boosting) : IgnoreInTraining;  Boost With inverse boostweight; Pair events with negative and positive weights in training sample and *annihilate* them (experimental!)]
SeparationType: "giniindex" [Separation criterion for node splitting]
# Default:
VerbosityLevel: "Default" [Verbosity level]
VarTransform: "None" [List of variable transformations performed before training, e.g., "D_Background,P_Signal,G,N_AllClasses" for: "Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)"]
IgnoreNegWeightsInTraining: "False" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]
NTrees: "50" [Number of trees in the forest]
MaxDepth: "3" [Max depth of the decision tree allowed]
MinNodeSize: "5%" [Minimum percentage of training events required in a leaf node (default: Classification: 5%, Regression: 0.2%)]
AdaBoostR2Loss: "quadratic" [Type of Loss function in AdaBoostR2]
UseBaggedBoost: "False" [Use only a random subsample of all events for growing the trees in each boost iteration.]
Shrinkage: "1.000000e+00" [Learning rate for GradBoost algorithm]
AdaBoostBeta: "6.000000e-01" [Learning rate  for AdaBoost algorithm]
UseRandomisedTrees: "False" [Determine at each node splitting the cut variable only as the best out of a random subset of variables (like in RandomForests)]
UseNvars: "3" [Size of the subset of variables used with RandomisedTree option]
UsePoissonNvars: "True" [Interpret "UseNvars" not as fixed number but as mean of a Poisson distribution in each split with RandomisedTree option]
BaggedSampleFraction: "6.000000e-01" [Relative size of bagged event sample to original size of the data sample (used whenever bagging is used (i.e. UseBaggedBoost, Bagging,)]
UseYesNoLeaf: "True" [Use Sig or Bkg categories, or the purity=S/(S+B) as classification of the leaf node -> Real-AdaBoost]
Css: "1.000000e+00" [AdaCost: cost of true signal selected signal]
Cts_sb: "1.000000e+00" [AdaCost: cost of true signal selected bkg]
Ctb_ss: "1.000000e+00" [AdaCost: cost of true bkg    selected signal]
Cbb: "1.000000e+00" [AdaCost: cost of true bkg    selected bkg ]
NodePurityLimit: "5.000000e-01" [In boosting/pruning, nodes with purity > NodePurityLimit are signal; background otherwise.]
RegressionLossFunctionBDTG: "huber" [Loss function for BDTG regression.]
HuberQuantile: "7.000000e-01" [In the Huber loss function this is the quantile that separates the core from the tails in the residuals distribution.]
DoBoostMonitor: "False" [Create control plot with ROC integral vs tree number]
UseFisherCuts: "False" [Use multivariate splits using the Fisher criterion]
MinLinCorrForFisher: "8.000000e-01" [The minimum linear correlation between two variables demanded for use in Fisher criterion in node splitting]
UseExclusiveVars: "False" [Variables already used in fisher criterion are not anymore analysed individually for node splitting]
DoPreselection: "False" [and and apply automatic pre-selection for 100% efficient signal (bkg) cuts prior to training]
SigToBkgFraction: "1.000000e+00" [Sig to Bkg ratio used in Training (similar to NodePurityLimit, which cannot be used in real adaboost]
PruneMethod: "nopruning" [Note: for BDTs use small trees (e.g.MaxDepth=3) and NoPruning:  Pruning: Method used for pruning (removal) of statistically insignificant branches ]
PruneStrength: "0.000000e+00" [Pruning strength]
PruningValFraction: "5.000000e-01" [Fraction of events to use for optimizing automatic pruning.]
SkipNormalization: "False" [Skip normalization at initialization, to keep expectation value of BDT output according to the fraction of events]
nEventsMin: "0" [deprecated: Use MinNodeSize (in % of training events) instead]
UseBaggedGrad: "False" [deprecated: Use *UseBaggedBoost* instead:  Use only a random subsample of all events for growing the trees in each iteration.]
GradBaggingFraction: "6.000000e-01" [deprecated: Use *BaggedSampleFraction* instead: Defines the fraction of events to be used in each iteration, e.g. when UseBaggedGrad=kTRUE. ]
UseNTrainEvents: "0" [deprecated: Use *BaggedSampleFraction* instead: Number of randomly picked training events used in randomised (and bagged) trees]
NNodesMax: "0" [deprecated: Use MaxDepth instead to limit the tree size]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 10
ystar                         ystar                         ystar                         ystar                                                           'F'    [-3.90205287933,4.21059513092]
mjj                           mjj                           mjj                           mjj                                                             'F'    [1000.0032959,8966.10839844]
j_qg[0]                       j_qg_0_                       j_qg[0]                       leadjet_qg                                                      'F'    [-1,1]
balance                       balance                       balance                       balance                                                         'F'    [0.478712558746,998.726013184]
circularity                   circularity                   circularity                   circularity                                                     'F'    [0.0044010928832,0.904844522476]
ht                            ht                            ht                            ht                                                              'F'    [96.9358978271,3740.47631836]
jjpt                          jjpt                          jjpt                          jjpt                                                            'F'    [6.57235145569,1512.05419922]
sphericity                    sphericity                    sphericity                    sphericity                                                      'F'    [0.00245522218756,0.818638980389]
dphijj                        dphijj                        dphijj                        dphijj                                                          'F'    [-3.14156651497,3.14120864868]
j_qg[1]                       j_qg_1_                       j_qg[1]                       subleadj_qg                                                     'F'    [-1,1]
NSpec 0


============================================================================ */

#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#define NN new BDT_VBF0HighVPtHighMJJNode
   
#ifndef BDT_VBF0HighVPtHighMJJNode__def
#define BDT_VBF0HighVPtHighMJJNode__def
   
class BDT_VBF0HighVPtHighMJJNode {
   
public:
   
   // constructor of an essentially "empty" node floating in space
   BDT_VBF0HighVPtHighMJJNode ( BDT_VBF0HighVPtHighMJJNode* left,BDT_VBF0HighVPtHighMJJNode* right,
                          int selector, double cutValue, bool cutType, 
                          int nodeType, double purity, double response ) :
   fLeft         ( left         ),
   fRight        ( right        ),
   fSelector     ( selector     ),
   fCutValue     ( cutValue     ),
   fCutType      ( cutType      ),
   fNodeType     ( nodeType     ),
   fPurity       ( purity       ),
   fResponse     ( response     ){
   }

   virtual ~BDT_VBF0HighVPtHighMJJNode();

   // test event if it descends the tree at this node to the right
   virtual bool GoesRight( const std::vector<double>& inputValues ) const;
   BDT_VBF0HighVPtHighMJJNode* GetRight( void )  {return fRight; };

   // test event if it descends the tree at this node to the left 
   virtual bool GoesLeft ( const std::vector<double>& inputValues ) const;
   BDT_VBF0HighVPtHighMJJNode* GetLeft( void ) { return fLeft; };   

   // return  S/(S+B) (purity) at this node (from  training)

   double GetPurity( void ) const { return fPurity; } 
   // return the node type
   int    GetNodeType( void ) const { return fNodeType; }
   double GetResponse(void) const {return fResponse;}

private:

   BDT_VBF0HighVPtHighMJJNode*   fLeft;     // pointer to the left daughter node
   BDT_VBF0HighVPtHighMJJNode*   fRight;    // pointer to the right daughter node
   int                     fSelector; // index of variable used in node selection (decision tree)   
   double                  fCutValue; // cut value applied on this node to discriminate bkg against sig
   bool                    fCutType;  // true: if event variable > cutValue ==> signal , false otherwise
   int                     fNodeType; // Type of node: -1 == Bkg-leaf, 1 == Signal-leaf, 0 = internal 
   double                  fPurity;   // Purity of node from training
   double                  fResponse; // Regression response value of node
}; 
   
//_______________________________________________________________________
   BDT_VBF0HighVPtHighMJJNode::~BDT_VBF0HighVPtHighMJJNode()
{
   if (fLeft  != NULL) delete fLeft;
   if (fRight != NULL) delete fRight;
}; 
   
//_______________________________________________________________________
bool BDT_VBF0HighVPtHighMJJNode::GoesRight( const std::vector<double>& inputValues ) const
{
   // test event if it descends the tree at this node to the right
   bool result;
     result = (inputValues[fSelector] > fCutValue );
   if (fCutType == true) return result; //the cuts are selecting Signal ;
   else return !result;
}
   
//_______________________________________________________________________
bool BDT_VBF0HighVPtHighMJJNode::GoesLeft( const std::vector<double>& inputValues ) const
{
   // test event if it descends the tree at this node to the left
   if (!this->GoesRight(inputValues)) return true;
   else return false;
}
   
#endif
   
#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() : fStatusIsClean( true ) {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;

   // returns classifier status
   bool IsStatusClean() const { return fStatusIsClean; }

 protected:

   bool fStatusIsClean;
};

#endif

class ReadBDT_VBF0HighVPtHighMJJ : public IClassifierReader {

 public:

   // constructor
   ReadBDT_VBF0HighVPtHighMJJ( std::vector<std::string>& theInputVars ) 
      : IClassifierReader(),
        fClassName( "ReadBDT_VBF0HighVPtHighMJJ" ),
        fNvars( 10 ),
        fIsNormalised( false )
   {      
      // the training input variables
      const char* inputVars[] = { "ystar", "mjj", "j_qg[0]", "balance", "circularity", "ht", "jjpt", "sphericity", "dphijj", "j_qg[1]" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = 0;
      fVmax[0] = 0;
      fVmin[1] = 0;
      fVmax[1] = 0;
      fVmin[2] = 0;
      fVmax[2] = 0;
      fVmin[3] = 0;
      fVmax[3] = 0;
      fVmin[4] = 0;
      fVmax[4] = 0;
      fVmin[5] = 0;
      fVmax[5] = 0;
      fVmin[6] = 0;
      fVmax[6] = 0;
      fVmin[7] = 0;
      fVmax[7] = 0;
      fVmin[8] = 0;
      fVmax[8] = 0;
      fVmin[9] = 0;
      fVmax[9] = 0;

      // initialize input variable types
      fType[0] = 'F';
      fType[1] = 'F';
      fType[2] = 'F';
      fType[3] = 'F';
      fType[4] = 'F';
      fType[5] = 'F';
      fType[6] = 'F';
      fType[7] = 'F';
      fType[8] = 'F';
      fType[9] = 'F';

      // initialize constants
      Initialize();

   }

   // destructor
   virtual ~ReadBDT_VBF0HighVPtHighMJJ() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the 
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const;

 private:

   // method-specific destructor
   void Clear();

   // common member variables
   const char* fClassName;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   const bool fIsNormalised;
   bool IsNormalised() const { return fIsNormalised; }
   double fVmin[10];
   double fVmax[10];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[10];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)
   std::vector<BDT_VBF0HighVPtHighMJJNode*> fForest;       // i.e. root nodes of decision trees
   std::vector<double>                fBoostWeights; // the weights applied in the individual boosts
};

double ReadBDT_VBF0HighVPtHighMJJ::GetMvaValue__( const std::vector<double>& inputValues ) const
{
   double myMVA = 0;
   double norm  = 0;
   for (unsigned int itree=0; itree<fForest.size(); itree++){
      BDT_VBF0HighVPtHighMJJNode *current = fForest[itree];
      while (current->GetNodeType() == 0) { //intermediate node
         if (current->GoesRight(inputValues)) current=(BDT_VBF0HighVPtHighMJJNode*)current->GetRight();
         else current=(BDT_VBF0HighVPtHighMJJNode*)current->GetLeft();
      }
      myMVA += fBoostWeights[itree] *  current->GetNodeType();
      norm  += fBoostWeights[itree];
   }
   return myMVA /= norm;
};

void ReadBDT_VBF0HighVPtHighMJJ::Initialize()
{
  // itree = 0
  fBoostWeights.push_back(0.339283616323409);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, -0.966704, 0, 1, 0.696206,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.551345,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.332772,-99) , 
2, 0.625769, 0, 0, 0.472712,-99) , 
1, 1668.94, 0, 0, 0.535861,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.257068,-99) , 
0, 1.55478, 1, 0, 0.5,-99)    );
  // itree = 1
  fBoostWeights.push_back(0.276284);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0.36973, 0, 1, 0.691412,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.56506,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.389323,-99) , 
0, 0.658804, 1, 0, 0.490314,-99) , 
NN(
0, 
0, 
-1, 90.5751, 1, -1, 0.333214,-99) , 
0, -0.963511, 0, 0, 0.45259,-99) , 
1, 2236.02, 0, 0, 0.476959,-99)    );
  // itree = 2
  fBoostWeights.push_back(0.257958);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.643002,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.477769,-99) , 
0, 1.24272, 1, 0, 0.609463,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.543404,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.393573,-99) , 
9, 0.831113, 0, 0, 0.465064,-99) , 
1, 1322.39, 0, 0, 0.539752,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.537272,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.383436,-99) , 
5, 784.788, 1, 0, 0.451865,-99) , 
NN(
0, 
0, 
-1, 0.936577, 0, -1, 0.329192,-99) , 
1, 1249.95, 0, 0, 0.404982,-99) , 
3, 73.0768, 1, 0, 0.479896,-99)    );
  // itree = 3
  fBoostWeights.push_back(0.125852);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 2281.53, 0, 1, 0.522211,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.307757,-99) , 
0, -1.8219, 0, 0, 0.50556,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.295905,-99) , 
2, 0.0647457, 0, 0, 0.484637,-99)    );
  // itree = 4
  fBoostWeights.push_back(0.191921);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 34.5794, 1, 1, 0.595992,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.409499,-99) , 
0, -0.966704, 0, 0, 0.546255,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.508451,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.348414,-99) , 
0, -1.3912, 0, 0, 0.482578,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.519869,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.36238,-99) , 
9, 0.996832, 0, 0, 0.389373,-99) , 
5, 611.433, 1, 0, 0.436282,-99) , 
1, 1701.85, 0, 0, 0.463699,-99)    );
  // itree = 5
  fBoostWeights.push_back(0.15057);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.659753,-99) , 
NN(
0, 
0, 
-1, 0.389297, 0, -1, 0.462048,-99) , 
1, 2363.08, 0, 0, 0.476787,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.337465,-99) , 
2, 0.111181, 0, 0, 0.458238,-99)    );
  // itree = 6
  fBoostWeights.push_back(0.162465);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.555771,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.441552,-99) , 
0, 1.56511, 1, 0, 0.540953,-99) , 
NN(
0, 
0, 
-1, 50.0378, 1, -1, 0.436343,-99) , 
9, 0.396893, 0, 0, 0.510779,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.373006,-99) , 
2, 0.111181, 0, 0, 0.49275,-99)    );
  // itree = 7
  fBoostWeights.push_back(0.165239);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.630866,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.549097,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.437153,-99) , 
6, 284.134, 1, 0, 0.501154,-99) , 
1, 1404.63, 0, 0, 0.555703,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.558856,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.468104,-99) , 
1, 1433.59, 0, 0, 0.506803,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.532555,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.399071,-99) , 
4, 0.48792, 0, 0, 0.432026,-99) , 
2, 0.853923, 0, 0, 0.470729,-99) , 
3, 32.8295, 1, 0, 0.489978,-99)    );
  // itree = 8
  fBoostWeights.push_back(0.114643);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.534387,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.4512,-99) , 
5, 1070.01, 1, 0, 0.516318,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.422535,-99) , 
0, -1.53546, 0, 0, 0.505383,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.386146,-99) , 
2, 0.0482821, 0, 0, 0.49632,-99)    );
  // itree = 9
  fBoostWeights.push_back(0.12351);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.579585,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.489057,-99) , 
2, 0.893117, 0, 0, 0.532894,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.638037,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.459821,-99) , 
1, 2371.29, 0, 0, 0.471326,-99) , 
8, 1.00215, 0, 0, 0.497722,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.381339,-99) , 
0, 1.85879, 1, 0, 0.488532,-99)    );
  // itree = 10
  fBoostWeights.push_back(0.116333);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.568651,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.496743,-99) , 
3, 73.0768, 1, 0, 0.536388,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.52605,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.407529,-99) , 
7, 0.155784, 0, 0, 0.474612,-99) , 
0, -0.640364, 0, 0, 0.51426,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.411219,-99) , 
0, 1.85879, 1, 0, 0.506197,-99)    );
  // itree = 11
  fBoostWeights.push_back(0.102376);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0.224069, 1, 1, 0.536521,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.576295,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.460644,-99) , 
9, 0.990513, 0, 0, 0.478444,-99) , 
0, -0.532949, 0, 0, 0.515694,-99) , 
NN(
0, 
0, 
-1, 0.421378, 0, -1, 0.436851,-99) , 
1, 1065.66, 0, 0, 0.505736,-99)    );
  // itree = 12
  fBoostWeights.push_back(0.0591972);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.621894,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.509558,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.428924,-99) , 
7, 0.0657358, 0, 0, 0.502127,-99) , 
1, 2637.49, 0, 0, 0.507292,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.41879,-99) , 
0, 1.85879, 1, 0, 0.500344,-99)    );
  // itree = 13
  fBoostWeights.push_back(0.0799624);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.599233,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.621064,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.49164,-99) , 
6, 295.269, 1, 0, 0.533246,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.501702,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.444711,-99) , 
4, 0.306626, 0, 0, 0.474662,-99) , 
7, 0.354662, 0, 0, 0.48542,-99) , 
1, 2637.49, 0, 0, 0.490268,-99)    );
  // itree = 14
  fBoostWeights.push_back(0.0862889);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 295.083, 1, 1, 0.539435,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.511717,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.416615,-99) , 
5, 966.951, 1, 0, 0.493132,-99) , 
NN(
0, 
0, 
-1, 1263.56, 0, -1, 0.432943,-99) , 
0, 1.07184, 1, 0, 0.479436,-99) , 
7, 0.354662, 0, 0, 0.490071,-99)    );
  // itree = 15
  fBoostWeights.push_back(0.115212);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.554616,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.548382,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.427922,-99) , 
5, 915.509, 1, 0, 0.512322,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.518602,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.44732,-99) , 
8, 2.46094, 0, 0, 0.464004,-99) , 
1, 1689.82, 0, 0, 0.475426,-99) , 
6, 493.267, 0, 0, 0.481961,-99)    );
  // itree = 16
  fBoostWeights.push_back(0.105256);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.607645,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.494595,-99) , 
4, 0.398067, 1, 0, 0.557885,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.582747,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.421226,-99) , 
5, 546.228, 1, 0, 0.474032,-99) , 
7, 0.178194, 0, 0, 0.519667,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.584782,-99) , 
NN(
0, 
0, 
-1, 0.609012, 1, -1, 0.469716,-99) , 
1, 2637.49, 0, 0, 0.475225,-99) , 
9, 0.965562, 0, 0, 0.488018,-99)    );
  // itree = 17
  fBoostWeights.push_back(0.0663926);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 600.408, 1, 1, 0.534364,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.51043,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.447169,-99) , 
8, 0.116965, 0, 0, 0.496746,-99) , 
8, -1.64354, 1, 0, 0.511248,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.445538,-99) , 
2, 0.0544074, 0, 0, 0.505972,-99)    );
  // itree = 18
  fBoostWeights.push_back(0.0560575);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.537142,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.493022,-99) , 
7, 0.27462, 0, 0, 0.506905,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.437495,-99) , 
4, 0.695522, 1, 0, 0.501529,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.446112,-99) , 
6, 163.686, 0, 0, 0.496118,-99)    );
  // itree = 19
  fBoostWeights.push_back(0.0904926);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0.539328, 1, 1, 0.577911,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.602109,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.477728,-99) , 
8, 1.90951, 0, 0, 0.499716,-99) , 
4, 0.417203, 0, 0, 0.526113,-99) , 
NN(
NN(
0, 
0, 
-1, 0.238567, 1, 1, 0.546599,-99) , 
NN(
0, 
0, 
-1, 0.138279, 0, -1, 0.47442,-99) , 
2, 0.996088, 0, 0, 0.488398,-99) , 
5, 521.547, 1, 0, 0.502907,-99)    );
  // itree = 20
  fBoostWeights.push_back(0.0678443);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.632678,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.493689,-99) , 
1, 1279.97, 0, 0, 0.564754,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.515354,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.430265,-99) , 
9, 0.0801741, 0, 0, 0.508698,-99) , 
3, 24.7952, 1, 0, 0.516735,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.454529,-99) , 
0, -1.86549, 0, 0, 0.512452,-99)    );
  // itree = 21
  fBoostWeights.push_back(0.0819828);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.591828,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.485476,-99) , 
0, 0.391884, 1, 0, 0.547821,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.566579,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.489499,-99) , 
5, 606.231, 1, 0, 0.515052,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.514987,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.460851,-99) , 
2, 0.712653, 1, 0, 0.481247,-99) , 
8, -1.64354, 1, 0, 0.494333,-99) , 
3, 24.7952, 1, 0, 0.502188,-99)    );
  // itree = 22
  fBoostWeights.push_back(0.0901936);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.567762,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.560761,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.46864,-99) , 
0, 0.248059, 1, 0, 0.517545,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.50118,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.360795,-99) , 
2, 0.718994, 1, 0, 0.481999,-99) , 
2, 0.813595, 0, 0, 0.50189,-99) , 
8, -2.96125, 1, 0, 0.506736,-99)    );
  // itree = 23
  fBoostWeights.push_back(0.121264);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.559209,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.490198,-99) , 
0, 0.26565, 1, 0, 0.526808,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.45001,-99) , 
4, 0.640998, 1, 0, 0.517127,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.621704,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.473644,-99) , 
0, 1.267, 1, 0, 0.53614,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.536031,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.426241,-99) , 
3, 32.3589, 1, 0, 0.447815,-99) , 
0, 0.700301, 0, 0, 0.47292,-99) , 
2, 0.815643, 0, 0, 0.497711,-99)    );
  // itree = 24
  fBoostWeights.push_back(0.0937723);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0.28036, 1, 1, 0.536028,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.453917,-99) , 
2, 0.111181, 0, 0, 0.525357,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.512374,-99) , 
NN(
0, 
0, 
-1, 0.310767, 0, -1, 0.444269,-99) , 
7, 0.263104, 0, 0, 0.465303,-99) , 
0, -0.640364, 0, 0, 0.505466,-99)    );
  // itree = 25
  fBoostWeights.push_back(0.0863352);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.583741,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.518821,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.440937,-99) , 
8, 2.08365, 1, 0, 0.497559,-99) , 
5, 836.32, 0, 0, 0.52361,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.612741,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.489919,-99) , 
6, 428.327, 0, 0, 0.500957,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.505653,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.403748,-99) , 
2, 0.961712, 0, 0, 0.440906,-99) , 
5, 965.522, 1, 0, 0.484624,-99) , 
0, 0.701656, 0, 0, 0.496855,-99)    );
  // itree = 26
  fBoostWeights.push_back(0.0352668);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.63372,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.551254,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.499662,-99) , 
6, 433.018, 0, 0, 0.504905,-99) , 
1, 2679.2, 0, 0, 0.509082,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.510946,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.430906,-99) , 
2, 0.938391, 0, 0, 0.465627,-99) , 
5, 1214.59, 1, 0, 0.502701,-99)    );
  // itree = 27
  fBoostWeights.push_back(0.0469086);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 2637.49, 0, 1, 0.515642,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.510751,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.435417,-99) , 
9, 0.957643, 0, 0, 0.466764,-99) , 
5, 1214.59, 1, 0, 0.508473,-99)    );
  // itree = 28
  fBoostWeights.push_back(0.092288);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 1.99409, 0, 1, 0.537606,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.448764,-99) , 
0, 1.12133, 1, 0, 0.516812,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.543014,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.521447,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.460125,-99) , 
4, 0.168973, 1, 0, 0.474804,-99) , 
0, 1.1681, 0, 0, 0.48745,-99) , 
5, 522.893, 1, 0, 0.498756,-99)    );
  // itree = 29
  fBoostWeights.push_back(0.0713895);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0.158468, 0, 1, 0.55198,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.511573,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.431786,-99) , 
6, 195.844, 0, 0, 0.494908,-99) , 
1, 1560.52, 0, 0, 0.512898,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.505389,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.435137,-99) , 
1, 1966.56, 1, 0, 0.493645,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.394519,-99) , 
2, 0.998277, 1, 0, 0.481011,-99) , 
4, 0.305736, 0, 0, 0.497492,-99)    );
  // itree = 30
  fBoostWeights.push_back(0.0671617);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.541959,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.481014,-99) , 
5, 804.456, 1, 0, 0.513528,-99) , 
NN(
0, 
0, 
-1, -1.3716, 0, -1, 0.479889,-99) , 
8, -1.6413, 1, 0, 0.492752,-99) , 
NN(
0, 
0, 
-1, 55.0795, 0, -1, 0.447395,-99) , 
1, 1065.66, 0, 0, 0.486989,-99)    );
  // itree = 31
  fBoostWeights.push_back(0.0712884);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.582442,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.51157,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.460053,-99) , 
6, 217.522, 0, 0, 0.496828,-99) , 
1, 2045.62, 0, 0, 0.506592,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.52633,-99) , 
NN(
0, 
0, 
-1, 0.266146, 1, -1, 0.459923,-99) , 
9, 0.97878, 0, 0, 0.476008,-99) , 
4, 0.190683, 0, 0, 0.497874,-99)    );
  // itree = 32
  fBoostWeights.push_back(0.0933896);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, -0.251491, 0, 1, 0.578353,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.519215,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.405005,-99) , 
5, 624.201, 1, 0, 0.484666,-99) , 
7, 0.19845, 0, 0, 0.517878,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.538054,-99) , 
NN(
0, 
0, 
-1, 0.137556, 0, -1, 0.471285,-99) , 
7, 0.100418, 1, 0, 0.481502,-99) , 
6, 240.687, 1, 0, 0.494231,-99)    );
  // itree = 33
  fBoostWeights.push_back(0.0960306);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0.359988, 0, 1, 0.546408,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.541629,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.4676,-99) , 
3, 85.8382, 0, 0, 0.492906,-99) , 
1, 1433.81, 0, 0, 0.511271,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.605008,-99) , 
NN(
0, 
0, 
-1, 96.7276, 1, -1, 0.464382,-99) , 
1, 2637.49, 0, 0, 0.475874,-99) , 
7, 0.13844, 0, 0, 0.499858,-99)    );
  // itree = 34
  fBoostWeights.push_back(0.0466526);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.612589,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.511027,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.452203,-99) , 
6, 164.492, 0, 0, 0.505105,-99) , 
1, 2726.54, 0, 0, 0.508124,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.457175,-99) , 
5, 1470.08, 1, 0, 0.5042,-99)    );
  // itree = 35
  fBoostWeights.push_back(0.0341729);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.54882,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.558234,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.495905,-99) , 
2, 0.996088, 0, 0, 0.499576,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.437374,-99) , 
2, 0.997837, 1, 0, 0.493755,-99) , 
2, 0.999269, 0, 0, 0.49644,-99)    );
  // itree = 36
  fBoostWeights.push_back(0.0495183);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 450.466, 1, 1, 0.549238,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.510488,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.478657,-99) , 
3, 56.0733, 0, 0, 0.499452,-99) , 
3, 24.7952, 1, 0, 0.506521,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.460811,-99) , 
0, -1.86549, 0, 0, 0.503312,-99)    );
  // itree = 37
  fBoostWeights.push_back(0.0795263);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 57.9332, 0, 1, 0.519559,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.421951,-99) , 
4, 0.695522, 1, 0, 0.511458,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.60006,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.480969,-99) , 
4, 0.487642, 0, 0, 0.510422,-99) , 
NN(
0, 
0, 
-1, 1.00184, 0, -1, 0.44941,-99) , 
9, 0.669666, 0, 0, 0.484604,-99) , 
3, 73.0768, 1, 0, 0.499532,-99)    );
  // itree = 38
  fBoostWeights.push_back(0.0539468);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.539711,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.517267,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.480684,-99) , 
6, 272.255, 1, 0, 0.497537,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.454733,-99) , 
7, 0.0660093, 0, 0, 0.493211,-99) , 
8, -2.96125, 1, 0, 0.496638,-99)    );
  // itree = 39
  fBoostWeights.push_back(0.0869756);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.599908,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.517279,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.461278,-99) , 
5, 564.927, 0, 0, 0.499662,-99) , 
3, 63.1619, 1, 0, 0.508664,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.705059,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.483311,-99) , 
0, -0.0468079, 0, 0, 0.510151,-99) , 
NN(
0, 
0, 
-1, 527.936, 1, -1, 0.453021,-99) , 
0, 0.286757, 1, 0, 0.484149,-99) , 
3, 56.0733, 0, 0, 0.497814,-99)    );
  // itree = 40
  fBoostWeights.push_back(0.0424922);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.570695,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.506124,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.444459,-99) , 
3, 116.435, 1, 0, 0.500273,-99) , 
3, 146.823, 0, 0, 0.505433,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.457798,-99) , 
3, 202.547, 1, 0, 0.501026,-99)    );
  // itree = 41
  fBoostWeights.push_back(0.0442972);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.534934,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.541241,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.490193,-99) , 
1, 2036.12, 0, 0, 0.496472,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.454647,-99) , 
8, -2.83555, 0, 0, 0.491521,-99) , 
4, 0.0644197, 1, 0, 0.494062,-99)    );
  // itree = 42
  fBoostWeights.push_back(0.0823604);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 2.1538, 0, 1, 0.5248,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.500095,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.441267,-99) , 
2, 0.931569, 1, 0, 0.469788,-99) , 
0, 1.09383, 1, 0, 0.511528,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.539247,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.480148,-99) , 
3, 180.43, 1, 0, 0.5168,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.518589,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.415534,-99) , 
3, 40.8752, 1, 0, 0.459761,-99) , 
3, 77.8414, 0, 0, 0.4912,-99) , 
5, 626.947, 1, 0, 0.501605,-99)    );
  // itree = 43
  fBoostWeights.push_back(0.0541341);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.586879,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.525758,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.456841,-99) , 
2, 0.898951, 0, 0, 0.487636,-99) , 
4, 0.254426, 1, 0, 0.520501,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.501655,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.444888,-99) , 
1, 1065.66, 0, 0, 0.493972,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.432976,-99) , 
3, 104.894, 1, 0, 0.486757,-99) , 
3, 133.129, 0, 0, 0.49299,-99)    );
  // itree = 44
  fBoostWeights.push_back(0.0810245);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.551431,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.457121,-99) , 
7, 0.163523, 0, 0, 0.517035,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.521628,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.472157,-99) , 
2, 0.951397, 0, 0, 0.492288,-99) , 
NN(
0, 
0, 
-1, -0.650253, 0, -1, 0.462813,-99) , 
4, 0.261802, 0, 0, 0.479645,-99) , 
3, 133.129, 0, 0, 0.486541,-99)    );
  // itree = 45
  fBoostWeights.push_back(0.0781248);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.583142,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.482164,-99) , 
7, 0.243152, 0, 0, 0.51725,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.536984,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.476899,-99) , 
1, 1668.94, 0, 0, 0.491528,-99) , 
0, 0.700301, 0, 0, 0.499439,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.505454,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.412971,-99) , 
7, 0.246542, 1, 0, 0.462652,-99) , 
2, 0.997837, 1, 0, 0.494385,-99)    );
  // itree = 46
  fBoostWeights.push_back(0.0881496);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.537854,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.46242,-99) , 
4, 0.531908, 1, 0, 0.521233,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.511475,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.437182,-99) , 
0, -0.818567, 0, 0, 0.488738,-99) , 
1, 1463.22, 1, 0, 0.508254,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.524537,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.426626,-99) , 
2, 0.999269, 0, 0, 0.461098,-99) , 
2, 0.997837, 1, 0, 0.501781,-99)    );
  // itree = 47
  fBoostWeights.push_back(0.0615009);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.570284,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.544534,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.488169,-99) , 
6, 433.018, 0, 0, 0.495113,-99) , 
1, 1816.45, 0, 0, 0.498826,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.536485,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.416361,-99) , 
4, 0.355108, 0, 0, 0.462183,-99) , 
1, 1965.55, 1, 0, 0.493337,-99)    );
  // itree = 48
  fBoostWeights.push_back(0.0773797);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, -1.04916, 1, 1, 0.517642,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.463506,-99) , 
2, 0.998877, 1, 0, 0.51281,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.586424,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.46565,-99) , 
6, 254.675, 0, 0, 0.504392,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.525929,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.382963,-99) , 
9, 0.793082, 0, 0, 0.444878,-99) , 
6, 308.845, 1, 0, 0.478614,-99) , 
1, 1600.16, 1, 0, 0.502625,-99)    );
  // itree = 49
  fBoostWeights.push_back(0.0404003);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.573087,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.504763,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.474691,-99) , 
2, 0.987601, 1, 0, 0.495768,-99) , 
1, 2679.2, 0, 0, 0.498191,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.503225,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.437369,-99) , 
2, 0.960885, 0, 0, 0.462467,-99) , 
5, 1214.59, 1, 0, 0.492964,-99)    );
   return;
};
 
// Clean up
inline void ReadBDT_VBF0HighVPtHighMJJ::Clear() 
{
   for (unsigned int itree=0; itree<fForest.size(); itree++) { 
      delete fForest[itree]; 
   }
}
   inline double ReadBDT_VBF0HighVPtHighMJJ::GetMvaValue( const std::vector<double>& inputValues ) const
   {
      // classifier response value
      double retval = 0;

      // classifier response, sanity check first
      if (!IsStatusClean()) {
         std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                   << " because status is dirty" << std::endl;
         retval = 0;
      }
      else {
         if (IsNormalised()) {
            // normalise variables
            std::vector<double> iV;
            iV.reserve(inputValues.size());
            int ivar = 0;
            for (std::vector<double>::const_iterator varIt = inputValues.begin();
                 varIt != inputValues.end(); varIt++, ivar++) {
               iV.push_back(NormVariable( *varIt, fVmin[ivar], fVmax[ivar] ));
            }
            retval = GetMvaValue__( iV );
         }
         else {
            retval = GetMvaValue__( inputValues );
         }
      }

      return retval;
   }
