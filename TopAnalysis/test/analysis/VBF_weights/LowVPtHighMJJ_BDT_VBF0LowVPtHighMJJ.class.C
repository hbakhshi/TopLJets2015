// Class: ReadBDT_VBF0LowVPtHighMJJ
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : BDT::BDT_VBF0LowVPtHighMJJ
TMVA Release   : 4.2.1         [262657]
ROOT Release   : 6.10/09       [395785]
Creator        : ajafari
Date           : Fri Jan 18 13:25:57 2019
Host           : Linux cmsbuild49.cern.ch 2.6.32-696.10.2.el6.x86_64 #1 SMP Thu Sep 14 16:35:02 CEST 2017 x86_64 x86_64 x86_64 GNU/Linux
Dir            : /afs/cern.ch/work/a/ajafari/Vjj/CMSSW_9_4_2/src/TopLJets2015/TopAnalysis/macro
Training events: 26262
Analysis type  : [Classification]


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
V: "False" [Verbose output (short form of "VerbosityLevel" below - overrides the latter one)]
H: "False" [Print method-specific help message]
CreateMVAPdfs: "True" [Create PDFs for classifier outputs (signal and background)]
nCuts: "0" [Number of grid points in variable range used in finding optimal cut in node splitting]
BoostType: "AdaBoost" [Boosting type for the trees in the forest (note: AdaCost is still experimental)]
NegWeightTreatment: "inverseboostnegweights" [How to treat events with negative weights in the BDT training (particular the boosting) : IgnoreInTraining;  Boost With inverse boostweight; Pair events with negative and positive weights in training sample and *annihilate* them (experimental!)]
SeparationType: "giniindex" [Separation criterion for node splitting]
# Default:
VerbosityLevel: "Default" [Verbosity level]
VarTransform: "None" [List of variable transformations performed before training, e.g., "D_Background,P_Signal,G,N_AllClasses" for: "Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)"]
IgnoreNegWeightsInTraining: "False" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]
NTrees: "50" [Number of trees in the forest]
MaxDepth: "3" [Max depth of the decision tree allowed]
MinNodeSize: "5%" [Minimum percentage of training events required in a leaf node (default: Classification: 5%, Regression: 0.2%)]
AdaBoostR2Loss: "quadratic" [Type of Loss function in AdaBoostR2]
UseBaggedBoost: "False" [Use only a random subsample of all events for growing the trees in each boost iteration.]
Shrinkage: "1.000000e+00" [Learning rate for GradBoost algorithm]
AdaBoostBeta: "6.000000e-01" [Learning rate  for AdaBoost algorithm]
UseRandomisedTrees: "False" [Determine at each node splitting the cut variable only as the best out of a random subset of variables (like in RandomForests)]
UseNvars: "4" [Size of the subset of variables used with RandomisedTree option]
UsePoissonNvars: "True" [Interpret "UseNvars" not as fixed number but as mean of a Poisson distribution in each split with RandomisedTree option]
BaggedSampleFraction: "6.000000e-01" [Relative size of bagged event sample to original size of the data sample (used whenever bagging is used (i.e. UseBaggedBoost, Bagging,)]
UseYesNoLeaf: "True" [Use Sig or Bkg categories, or the purity=S/(S+B) as classification of the leaf node -> Real-AdaBoost]
Css: "1.000000e+00" [AdaCost: cost of true signal selected signal]
Cts_sb: "1.000000e+00" [AdaCost: cost of true signal selected bkg]
Ctb_ss: "1.000000e+00" [AdaCost: cost of true bkg    selected signal]
Cbb: "1.000000e+00" [AdaCost: cost of true bkg    selected bkg ]
NodePurityLimit: "5.000000e-01" [In boosting/pruning, nodes with purity > NodePurityLimit are signal; background otherwise.]
RegressionLossFunctionBDTG: "huber" [Loss function for BDTG regression.]
HuberQuantile: "7.000000e-01" [In the Huber loss function this is the quantile that separates the core from the tails in the residuals distribution.]
DoBoostMonitor: "False" [Create control plot with ROC integral vs tree number]
UseFisherCuts: "False" [Use multivariate splits using the Fisher criterion]
MinLinCorrForFisher: "8.000000e-01" [The minimum linear correlation between two variables demanded for use in Fisher criterion in node splitting]
UseExclusiveVars: "False" [Variables already used in fisher criterion are not anymore analysed individually for node splitting]
DoPreselection: "False" [and and apply automatic pre-selection for 100% efficient signal (bkg) cuts prior to training]
SigToBkgFraction: "1.000000e+00" [Sig to Bkg ratio used in Training (similar to NodePurityLimit, which cannot be used in real adaboost]
PruneMethod: "nopruning" [Note: for BDTs use small trees (e.g.MaxDepth=3) and NoPruning:  Pruning: Method used for pruning (removal) of statistically insignificant branches ]
PruneStrength: "0.000000e+00" [Pruning strength]
PruningValFraction: "5.000000e-01" [Fraction of events to use for optimizing automatic pruning.]
SkipNormalization: "False" [Skip normalization at initialization, to keep expectation value of BDT output according to the fraction of events]
nEventsMin: "0" [deprecated: Use MinNodeSize (in % of training events) instead]
UseBaggedGrad: "False" [deprecated: Use *UseBaggedBoost* instead:  Use only a random subsample of all events for growing the trees in each iteration.]
GradBaggingFraction: "6.000000e-01" [deprecated: Use *BaggedSampleFraction* instead: Defines the fraction of events to be used in each iteration, e.g. when UseBaggedGrad=kTRUE. ]
UseNTrainEvents: "0" [deprecated: Use *BaggedSampleFraction* instead: Number of randomly picked training events used in randomised (and bagged) trees]
NNodesMax: "0" [deprecated: Use MaxDepth instead to limit the tree size]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 12
forwardeta                    forwardeta                    forwardeta                    forwardeta                                                      'F'    [1.52188551426,4.68287611008]
mjj                           mjj                           mjj                           mjj                                                             'F'    [1000.02545166,9690.50488281]
jjpt                          jjpt                          jjpt                          jjpt                                                            'F'    [1.5927734375,636.596374512]
dphijj                        dphijj                        dphijj                        dphijj                                                          'F'    [-3.14146089554,3.14152264595]
ystar                         ystar                         ystar                         ystar                                                           'F'    [-3.5614168644,3.07476449013]
dphibjj                       dphibjj                       dphibjj                       dphibjj                                                         'F'    [-3.14157533646,3.14157009125]
balance                       balance                       balance                       balance                                                         'F'    [0.323038250208,587.776916504]
j_qg[0]                       j_qg_0_                       j_qg[0]                       leadjet_qg                                                      'F'    [-1,1]
j_qg[1]                       j_qg_1_                       j_qg[1]                       subleadjet_qg                                                   'F'    [-1,1]
dphivj0                       dphivj0                       dphivj0                       dphivj0                                                         'F'    [0.00175261497498,3.14147353172]
ht                            ht                            ht                            ht                                                              'F'    [80.6170196533,1739.7734375]
C                             C                             C                             C                                                               'F'    [0.0107004772872,0.72715306282]
NSpec 0


============================================================================ */

#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#define NN new BDT_VBF0LowVPtHighMJJNode
   
#ifndef BDT_VBF0LowVPtHighMJJNode__def
#define BDT_VBF0LowVPtHighMJJNode__def
   
class BDT_VBF0LowVPtHighMJJNode {
   
public:
   
   // constructor of an essentially "empty" node floating in space
   BDT_VBF0LowVPtHighMJJNode ( BDT_VBF0LowVPtHighMJJNode* left,BDT_VBF0LowVPtHighMJJNode* right,
                          int selector, double cutValue, bool cutType, 
                          int nodeType, double purity, double response ) :
   fLeft         ( left         ),
   fRight        ( right        ),
   fSelector     ( selector     ),
   fCutValue     ( cutValue     ),
   fCutType      ( cutType      ),
   fNodeType     ( nodeType     ),
   fPurity       ( purity       ),
   fResponse     ( response     ){
   }

   virtual ~BDT_VBF0LowVPtHighMJJNode();

   // test event if it descends the tree at this node to the right
   virtual bool GoesRight( const std::vector<double>& inputValues ) const;
   BDT_VBF0LowVPtHighMJJNode* GetRight( void )  {return fRight; };

   // test event if it descends the tree at this node to the left 
   virtual bool GoesLeft ( const std::vector<double>& inputValues ) const;
   BDT_VBF0LowVPtHighMJJNode* GetLeft( void ) { return fLeft; };   

   // return  S/(S+B) (purity) at this node (from  training)

   double GetPurity( void ) const { return fPurity; } 
   // return the node type
   int    GetNodeType( void ) const { return fNodeType; }
   double GetResponse(void) const {return fResponse;}

private:

   BDT_VBF0LowVPtHighMJJNode*   fLeft;     // pointer to the left daughter node
   BDT_VBF0LowVPtHighMJJNode*   fRight;    // pointer to the right daughter node
   int                     fSelector; // index of variable used in node selection (decision tree)   
   double                  fCutValue; // cut value applied on this node to discriminate bkg against sig
   bool                    fCutType;  // true: if event variable > cutValue ==> signal , false otherwise
   int                     fNodeType; // Type of node: -1 == Bkg-leaf, 1 == Signal-leaf, 0 = internal 
   double                  fPurity;   // Purity of node from training
   double                  fResponse; // Regression response value of node
}; 
   
//_______________________________________________________________________
   BDT_VBF0LowVPtHighMJJNode::~BDT_VBF0LowVPtHighMJJNode()
{
   if (fLeft  != NULL) delete fLeft;
   if (fRight != NULL) delete fRight;
}; 
   
//_______________________________________________________________________
bool BDT_VBF0LowVPtHighMJJNode::GoesRight( const std::vector<double>& inputValues ) const
{
   // test event if it descends the tree at this node to the right
   bool result;
     result = (inputValues[fSelector] > fCutValue );
   if (fCutType == true) return result; //the cuts are selecting Signal ;
   else return !result;
}
   
//_______________________________________________________________________
bool BDT_VBF0LowVPtHighMJJNode::GoesLeft( const std::vector<double>& inputValues ) const
{
   // test event if it descends the tree at this node to the left
   if (!this->GoesRight(inputValues)) return true;
   else return false;
}
   
#endif
   
#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() : fStatusIsClean( true ) {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;

   // returns classifier status
   bool IsStatusClean() const { return fStatusIsClean; }

 protected:

   bool fStatusIsClean;
};

#endif

class ReadBDT_VBF0LowVPtHighMJJ : public IClassifierReader {

 public:

   // constructor
   ReadBDT_VBF0LowVPtHighMJJ( std::vector<std::string>& theInputVars ) 
      : IClassifierReader(),
        fClassName( "ReadBDT_VBF0LowVPtHighMJJ" ),
        fNvars( 12 ),
        fIsNormalised( false )
   {      
      // the training input variables
      const char* inputVars[] = { "forwardeta", "mjj", "jjpt", "dphijj", "ystar", "dphibjj", "balance", "j_qg[0]", "j_qg[1]", "dphivj0", "ht", "C" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = 0;
      fVmax[0] = 0;
      fVmin[1] = 0;
      fVmax[1] = 0;
      fVmin[2] = 0;
      fVmax[2] = 0;
      fVmin[3] = 0;
      fVmax[3] = 0;
      fVmin[4] = 0;
      fVmax[4] = 0;
      fVmin[5] = 0;
      fVmax[5] = 0;
      fVmin[6] = 0;
      fVmax[6] = 0;
      fVmin[7] = 0;
      fVmax[7] = 0;
      fVmin[8] = 0;
      fVmax[8] = 0;
      fVmin[9] = 0;
      fVmax[9] = 0;
      fVmin[10] = 0;
      fVmax[10] = 0;
      fVmin[11] = 0;
      fVmax[11] = 0;

      // initialize input variable types
      fType[0] = 'F';
      fType[1] = 'F';
      fType[2] = 'F';
      fType[3] = 'F';
      fType[4] = 'F';
      fType[5] = 'F';
      fType[6] = 'F';
      fType[7] = 'F';
      fType[8] = 'F';
      fType[9] = 'F';
      fType[10] = 'F';
      fType[11] = 'F';

      // initialize constants
      Initialize();

   }

   // destructor
   virtual ~ReadBDT_VBF0LowVPtHighMJJ() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the 
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const;

 private:

   // method-specific destructor
   void Clear();

   // common member variables
   const char* fClassName;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   const bool fIsNormalised;
   bool IsNormalised() const { return fIsNormalised; }
   double fVmin[12];
   double fVmax[12];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[12];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)
   std::vector<BDT_VBF0LowVPtHighMJJNode*> fForest;       // i.e. root nodes of decision trees
   std::vector<double>                fBoostWeights; // the weights applied in the individual boosts
};

double ReadBDT_VBF0LowVPtHighMJJ::GetMvaValue__( const std::vector<double>& inputValues ) const
{
   double myMVA = 0;
   double norm  = 0;
   for (unsigned int itree=0; itree<fForest.size(); itree++){
      BDT_VBF0LowVPtHighMJJNode *current = fForest[itree];
      while (current->GetNodeType() == 0) { //intermediate node
         if (current->GoesRight(inputValues)) current=(BDT_VBF0LowVPtHighMJJNode*)current->GetRight();
         else current=(BDT_VBF0LowVPtHighMJJNode*)current->GetLeft();
      }
      myMVA += fBoostWeights[itree] *  current->GetNodeType();
      norm  += fBoostWeights[itree];
   }
   return myMVA /= norm;
};

void ReadBDT_VBF0LowVPtHighMJJ::Initialize()
{
  // itree = 0
  fBoostWeights.push_back(0.386906300553049);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 83.8899, 1, 1, 0.734443,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.607284,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.368583,-99) , 
4, -1.16406, 0, 0, 0.558937,-99) , 
NN(
0, 
0, 
-1, 3.28578, 1, -1, 0.348701,-99) , 
6, 41.0009, 1, 0, 0.437265,-99) , 
1, 1734.24, 0, 0, 0.5,-99)    );
  // itree = 1
  fBoostWeights.push_back(0.313504);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.646323,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.48591,-99) , 
1, 1231.99, 0, 0, 0.583123,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.247076,-99) , 
4, -1.68129, 0, 0, 0.545473,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.274308,-99) , 
4, 1.39518, 1, 0, 0.507958,-99)    );
  // itree = 2
  fBoostWeights.push_back(0.274566);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 56.4433, 1, 1, 0.598693,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.346035,-99) , 
4, -1.50037, 0, 0, 0.55811,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.53593,-99) , 
NN(
0, 
0, 
-1, 2.68236, 1, -1, 0.350816,-99) , 
1, 1694, 0, 0, 0.386171,-99) , 
4, 0.940705, 1, 0, 0.516156,-99)    );
  // itree = 3
  fBoostWeights.push_back(0.222731);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.777782,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.56904,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.419877,-99) , 
4, 0.787762, 1, 0, 0.522558,-99) , 
1, 2134.27, 0, 0, 0.544321,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.514683,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.325022,-99) , 
10, 583.465, 1, 0, 0.472158,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.318118,-99) , 
0, 3.41489, 1, 0, 0.421137,-99) , 
6, 56.0072, 1, 0, 0.491608,-99)    );
  // itree = 4
  fBoostWeights.push_back(0.194268);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 2371.44, 0, 1, 0.554492,-99) , 
NN(
0, 
0, 
-1, -0.508062, 0, -1, 0.417102,-99) , 
6, 77.079, 1, 0, 0.516789,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.515465,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.366887,-99) , 
6, 73.6964, 1, 0, 0.465745,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.279148,-99) , 
10, 250.153, 0, 0, 0.396061,-99) , 
9, 2.82846, 1, 0, 0.477041,-99)    );
  // itree = 5
  fBoostWeights.push_back(0.173556);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.70919,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.513171,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.402121,-99) , 
4, -0.91288, 0, 0, 0.484405,-99) , 
6, 12.7157, 1, 0, 0.498378,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.555804,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.408836,-99) , 
0, 3.09214, 0, 0, 0.48892,-99) , 
NN(
0, 
0, 
-1, 2.34079, 0, -1, 0.349088,-99) , 
3, -1.68556, 1, 0, 0.398831,-99) , 
8, 0.415705, 0, 0, 0.464863,-99)    );
  // itree = 6
  fBoostWeights.push_back(0.143716);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.666413,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.480443,-99) , 
6, 13.6337, 1, 0, 0.493803,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.331427,-99) , 
4, 1.62365, 1, 0, 0.478187,-99) , 
NN(
0, 
0, 
-1, 360.344, 1, -1, 0.346668,-99) , 
7, 0.200439, 0, 0, 0.458834,-99)    );
  // itree = 7
  fBoostWeights.push_back(0.159783);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.636445,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.543425,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.451881,-99) , 
0, 3.13682, 1, 0, 0.497474,-99) , 
NN(
0, 
0, 
-1, 337.356, 1, -1, 0.372417,-99) , 
7, 0.228275, 0, 0, 0.476966,-99) , 
1, 2134.27, 0, 0, 0.491397,-99)    );
  // itree = 8
  fBoostWeights.push_back(0.203467);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.687493,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.558525,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.461032,-99) , 
4, -0.289765, 0, 0, 0.515609,-99) , 
10, 184.474, 1, 0, 0.532722,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.610074,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.454106,-99) , 
0, 2.58946, 0, 0, 0.552295,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.526853,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.313127,-99) , 
3, -2.24317, 1, 0, 0.406252,-99) , 
3, 2.45961, 0, 0, 0.447765,-99) , 
9, 2.68339, 1, 0, 0.49408,-99)    );
  // itree = 9
  fBoostWeights.push_back(0.161276);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, -0.118662, 0, 1, 0.554635,-99) , 
NN(
0, 
0, 
-1, 0.613655, 0, -1, 0.45274,-99) , 
4, 0.433753, 1, 0, 0.51473,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.562759,-99) , 
NN(
0, 
0, 
-1, -2.28209, 1, -1, 0.383343,-99) , 
3, 2.71599, 0, 0, 0.424461,-99) , 
9, 2.86313, 1, 0, 0.488882,-99)    );
  // itree = 10
  fBoostWeights.push_back(0.0790681);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.679745,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.507021,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.389796,-99) , 
4, 1.62365, 1, 0, 0.495885,-99) , 
1, 2727, 0, 0, 0.502372,-99) , 
NN(
0, 
0, 
-1, 322.96, 1, -1, 0.393961,-99) , 
7, 0.16602, 0, 0, 0.48896,-99)    );
  // itree = 11
  fBoostWeights.push_back(0.121026);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.645047,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.517443,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.455387,-99) , 
3, 1.80033, 0, 0, 0.480031,-99) , 
1, 2227.01, 0, 0, 0.490844,-99) , 
NN(
0, 
0, 
-1, 0.750084, 0, -1, 0.393512,-99) , 
10, 512.506, 1, 0, 0.477227,-99)    );
  // itree = 12
  fBoostWeights.push_back(0.120752);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.641013,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.522499,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.389684,-99) , 
11, 0.0882317, 0, 0, 0.502728,-99) , 
10, 212.688, 1, 0, 0.521672,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.503937,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.383088,-99) , 
4, -1.25332, 0, 0, 0.481352,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.325668,-99) , 
3, 1.33182, 0, 0, 0.455074,-99) , 
3, -1.24054, 1, 0, 0.484865,-99)    );
  // itree = 13
  fBoostWeights.push_back(0.12292);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.622905,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.62946,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.481253,-99) , 
10, 212.688, 1, 0, 0.497932,-99) , 
NN(
0, 
0, 
-1, 1.81394, 0, -1, 0.439464,-99) , 
3, -1.7392, 1, 0, 0.463421,-99) , 
1, 2727, 0, 0, 0.468822,-99)    );
  // itree = 14
  fBoostWeights.push_back(0.104605);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 19.5429, 1, 1, 0.559067,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.509457,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.382488,-99) , 
11, 0.118073, 0, 0, 0.48436,-99) , 
1, 1541.08, 0, 0, 0.505993,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.500458,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.380136,-99) , 
5, -1.23344, 1, 0, 0.431014,-99) , 
8, 0.178244, 0, 0, 0.494939,-99)    );
  // itree = 15
  fBoostWeights.push_back(0.106572);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.583008,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.486252,-99) , 
10, 206.805, 1, 0, 0.501674,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.535699,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.392516,-99) , 
3, -2.33106, 1, 0, 0.437804,-99) , 
9, 2.91706, 1, 0, 0.486762,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.384389,-99) , 
7, 0.0900426, 0, 0, 0.47944,-99)    );
  // itree = 16
  fBoostWeights.push_back(0.116125);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 27.9881, 1, 1, 0.564524,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.522402,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.444781,-99) , 
10, 361.924, 1, 0, 0.49491,-99) , 
7, 0.978196, 0, 0, 0.512425,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.52679,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.455852,-99) , 
10, 379.8, 1, 0, 0.488547,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.387534,-99) , 
10, 276.972, 0, 0, 0.443937,-99) , 
9, 2.91706, 1, 0, 0.496524,-99)    );
  // itree = 17
  fBoostWeights.push_back(0.108523);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.659171,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.519053,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.413717,-99) , 
8, 0.178244, 0, 0, 0.501445,-99) , 
6, 18.9434, 1, 0, 0.519746,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.522201,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.458156,-99) , 
7, 0.92343, 0, 0, 0.484963,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.397973,-99) , 
10, 196.474, 0, 0, 0.47049,-99) , 
1, 1426.29, 0, 0, 0.48934,-99)    );
  // itree = 18
  fBoostWeights.push_back(0.109202);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 1316.85, 0, 1, 0.575135,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.507468,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.42675,-99) , 
4, -0.367568, 0, 0, 0.473684,-99) , 
3, -2.77153, 0, 0, 0.52226,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.594991,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.501161,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.433262,-99) , 
3, 2.346, 0, 0, 0.463103,-99) , 
6, 12.7157, 1, 0, 0.470977,-99) , 
3, -2.28531, 1, 0, 0.487089,-99)    );
  // itree = 19
  fBoostWeights.push_back(0.0747489);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.579872,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.502999,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.449105,-99) , 
11, 0.146245, 0, 0, 0.482749,-99) , 
1, 2134.27, 0, 0, 0.490002,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.392061,-99) , 
10, 613.919, 1, 0, 0.483224,-99)    );
  // itree = 20
  fBoostWeights.push_back(0.0843801);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.527332,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.476405,-99) , 
0, 3.4211, 0, 0, 0.49195,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.404291,-99) , 
11, 0.0677886, 0, 0, 0.485677,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.401673,-99) , 
4, 1.7109, 1, 0, 0.479196,-99)    );
  // itree = 21
  fBoostWeights.push_back(0.0493358);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.592228,-99) , 
NN(
0, 
0, 
-1, 1.6373, 1, -1, 0.490458,-99) , 
6, 12.7222, 1, 0, 0.49645,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.420063,-99) , 
4, -1.68129, 0, 0, 0.489299,-99)    );
  // itree = 22
  fBoostWeights.push_back(0.0853507);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 212.632, 1, 1, 0.540626,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.466486,-99) , 
1, 1098.87, 0, 0, 0.524563,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.633097,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.489009,-99) , 
1, 2277.13, 0, 0, 0.497616,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.394362,-99) , 
3, 1.33182, 0, 0, 0.480704,-99) , 
3, -1.24054, 1, 0, 0.500362,-99)    );
  // itree = 23
  fBoostWeights.push_back(0.0956411);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.533147,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.451928,-99) , 
7, 0.211, 0, 0, 0.520906,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.446379,-99) , 
4, 1.57393, 1, 0, 0.51261,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.437478,-99) , 
4, -1.68129, 0, 0, 0.505601,-99)    );
  // itree = 24
  fBoostWeights.push_back(0.0955074);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.676722,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.541533,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.479436,-99) , 
5, -2.38511, 1, 0, 0.501974,-99) , 
10, 184.474, 1, 0, 0.516681,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.514104,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.442608,-99) , 
4, -0.72754, 0, 0, 0.490847,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.40477,-99) , 
10, 198.248, 0, 0, 0.477266,-99) , 
9, 2.61467, 1, 0, 0.496793,-99)    );
  // itree = 25
  fBoostWeights.push_back(0.0992157);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.661405,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.545214,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.492659,-99) , 
1, 1539.34, 0, 0, 0.508921,-99) , 
10, 181.553, 1, 0, 0.520784,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.640298,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.475613,-99) , 
4, -0.118567, 0, 0, 0.501608,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.504426,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.411183,-99) , 
5, 2.85302, 0, 0, 0.438166,-99) , 
4, 0.31907, 1, 0, 0.473932,-99) , 
9, 2.61467, 1, 0, 0.497142,-99)    );
  // itree = 26
  fBoostWeights.push_back(0.0839639);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.673686,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.610719,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.49894,-99) , 
4, -0.118662, 0, 0, 0.513742,-99) , 
10, 184.385, 1, 0, 0.526256,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.553716,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.477031,-99) , 
11, 0.203047, 0, 0, 0.500998,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.394958,-99) , 
9, 3.00642, 1, 0, 0.485143,-99) , 
4, 0.213348, 1, 0, 0.507707,-99)    );
  // itree = 27
  fBoostWeights.push_back(0.109055);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.658173,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.553138,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.486469,-99) , 
8, 0.485085, 0, 0, 0.529435,-99) , 
10, 182.699, 1, 0, 0.538964,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.532183,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.459788,-99) , 
6, 29.8638, 0, 0, 0.508913,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.415248,-99) , 
9, 3.00642, 1, 0, 0.494981,-99) , 
4, 0.213348, 1, 0, 0.519134,-99)    );
  // itree = 28
  fBoostWeights.push_back(0.0812527);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 2134.27, 0, 1, 0.543855,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.51368,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.415068,-99) , 
0, 3.96974, 1, 0, 0.500933,-99) , 
3, 1.81394, 0, 0, 0.518117,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.432045,-99) , 
10, 613.919, 1, 0, 0.512201,-99)    );
  // itree = 29
  fBoostWeights.push_back(0.0863445);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.627251,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.515936,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.422312,-99) , 
11, 0.0784317, 0, 0, 0.506407,-99) , 
10, 182.699, 1, 0, 0.515167,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.579445,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.479446,-99) , 
10, 380.568, 1, 0, 0.530024,-99) , 
NN(
0, 
0, 
-1, 82.4162, 0, -1, 0.458962,-99) , 
3, 2.48708, 0, 0, 0.476282,-99) , 
4, 0.213348, 1, 0, 0.497615,-99)    );
  // itree = 30
  fBoostWeights.push_back(0.0421736);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.62425,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.500769,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.43229,-99) , 
7, 0.998461, 1, 0, 0.495795,-99) , 
5, -3.00613, 1, 0, 0.501763,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.516041,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.398161,-99) , 
9, 2.70143, 1, 0, 0.445949,-99) , 
5, -3.05515, 0, 0, 0.49535,-99)    );
  // itree = 31
  fBoostWeights.push_back(0.116619);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0.109279, 1, 1, 0.566176,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.503512,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.387819,-99) , 
7, 0.819388, 0, 0, 0.446911,-99) , 
10, 293.407, 1, 0, 0.515844,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.572043,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.472643,-99) , 
2, 94.3814, 1, 0, 0.504444,-99) , 
NN(
0, 
0, 
-1, 306.243, 0, -1, 0.454411,-99) , 
7, 0.816998, 1, 0, 0.477853,-99) , 
6, 27.8275, 1, 0, 0.487534,-99)    );
  // itree = 32
  fBoostWeights.push_back(0.103645);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 49.0962, 0, 1, 0.53277,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.550041,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.467685,-99) , 
9, 2.36507, 1, 0, 0.48861,-99) , 
3, 1.45296, 0, 0, 0.507601,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.594455,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.455785,-99) , 
10, 252.193, 1, 0, 0.510295,-99) , 
NN(
0, 
0, 
-1, 3.09984, 1, -1, 0.428509,-99) , 
7, 0.850496, 1, 0, 0.470131,-99) , 
2, 83.0712, 0, 0, 0.4984,-99)    );
  // itree = 33
  fBoostWeights.push_back(0.0652822);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.621228,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.523008,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.483602,-99) , 
3, -1.74012, 1, 0, 0.499971,-99) , 
5, -3.00613, 1, 0, 0.505576,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.504457,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.414446,-99) , 
9, 2.70143, 1, 0, 0.450834,-99) , 
5, -3.05515, 0, 0, 0.499304,-99)    );
  // itree = 34
  fBoostWeights.push_back(0.056589);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.577601,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.50903,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.464978,-99) , 
5, -2.6877, 0, 0, 0.500383,-99) , 
5, -2.95717, 1, 0, 0.507478,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.506711,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.419926,-99) , 
1, 1385.76, 0, 0, 0.453817,-99) , 
5, -3.05515, 0, 0, 0.501341,-99)    );
  // itree = 35
  fBoostWeights.push_back(0.0868965);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.568054,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.539091,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.482103,-99) , 
3, 1.76037, 0, 0, 0.50547,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.518702,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.42669,-99) , 
10, 280.895, 1, 0, 0.474248,-99) , 
6, 44.0546, 0, 0, 0.491142,-99) , 
1, 2727, 0, 0, 0.493631,-99)    );
  // itree = 36
  fBoostWeights.push_back(0.0996108);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.532046,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.432914,-99) , 
6, 142.322, 1, 0, 0.519291,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.447041,-99) , 
10, 220.514, 0, 0, 0.508487,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.561821,-99) , 
NN(
0, 
0, 
-1, 2.21395, 0, -1, 0.459596,-99) , 
1, 1693.01, 0, 0, 0.478102,-99) , 
6, 44.0546, 0, 0, 0.49465,-99)    );
  // itree = 37
  fBoostWeights.push_back(0.0929422);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.526475,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.452082,-99) , 
1, 1070.27, 0, 0, 0.514074,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.52147,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.419447,-99) , 
7, 0.824036, 1, 0, 0.467845,-99) , 
2, 83.1142, 0, 0, 0.502115,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.508794,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.375242,-99) , 
5, 2.29629, 1, 0, 0.455557,-99) , 
10, 508.248, 1, 0, 0.495346,-99)    );
  // itree = 38
  fBoostWeights.push_back(0.100476);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.566393,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.486283,-99) , 
1, 1082.74, 0, 0, 0.542946,-99) , 
NN(
0, 
0, 
-1, 40.7151, 0, -1, 0.446258,-99) , 
7, 0.781483, 0, 0, 0.502933,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.590782,-99) , 
NN(
0, 
0, 
-1, 510.03, 1, -1, 0.46754,-99) , 
5, 3.07546, 0, 0, 0.475573,-99) , 
11, 0.20072, 0, 0, 0.485071,-99)    );
  // itree = 39
  fBoostWeights.push_back(0.0537431);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.599728,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.544244,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.493498,-99) , 
10, 206.035, 1, 0, 0.500723,-99) , 
5, 2.96454, 0, 0, 0.507296,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.510813,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.398228,-99) , 
5, 3.07556, 0, 0, 0.459898,-99) , 
5, 3.03214, 1, 0, 0.500833,-99)    );
  // itree = 40
  fBoostWeights.push_back(0.0455067);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 2.97221, 0, 1, 0.515399,-99) , 
NN(
0, 
0, 
-1, 107.173, 0, -1, 0.458507,-99) , 
5, 3.03214, 1, 0, 0.507653,-99)    );
  // itree = 41
  fBoostWeights.push_back(0.057883);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.575485,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.507894,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.466242,-99) , 
9, 2.21367, 0, 0, 0.49861,-99) , 
0, 2.23576, 1, 0, 0.505059,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.527956,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.428624,-99) , 
11, 0.210348, 0, 0, 0.465855,-99) , 
10, 508.248, 1, 0, 0.499377,-99)    );
  // itree = 42
  fBoostWeights.push_back(0.0469916);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.56563,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.501263,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.45892,-99) , 
0, 3.58057, 1, 0, 0.490787,-99) , 
5, -2.95717, 1, 0, 0.497626,-99) , 
NN(
0, 
0, 
-1, 2.70143, 1, -1, 0.45361,-99) , 
5, -3.05515, 0, 0, 0.492576,-99)    );
  // itree = 43
  fBoostWeights.push_back(0.0580753);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.564762,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.506722,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.468932,-99) , 
9, 2.64245, 1, 0, 0.488898,-99) , 
5, 2.97221, 0, 0, 0.493369,-99) , 
NN(
0, 
0, 
-1, 107.173, 0, -1, 0.455296,-99) , 
5, 3.03214, 1, 0, 0.488193,-99)    );
  // itree = 44
  fBoostWeights.push_back(0.0640996);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.552824,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.511203,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.475937,-99) , 
11, 0.137178, 1, 0, 0.488732,-99) , 
0, 2.23576, 1, 0, 0.494089,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.513225,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.420903,-99) , 
8, 0.745766, 1, 0, 0.457263,-99) , 
10, 508.248, 1, 0, 0.488748,-99)    );
  // itree = 45
  fBoostWeights.push_back(0.0973993);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0.732351, 0, 1, 0.548905,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.513159,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.431344,-99) , 
0, 2.87507, 0, 0, 0.481688,-99) , 
8, 0.784458, 0, 0, 0.510112,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.555486,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.450092,-99) , 
0, 2.63024, 0, 0, 0.513857,-99) , 
NN(
0, 
0, 
-1, 0.76853, 1, -1, 0.465477,-99) , 
3, -2.28519, 1, 0, 0.480726,-99) , 
1, 1198.69, 1, 0, 0.491534,-99)    );
  // itree = 46
  fBoostWeights.push_back(0.0367864);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.584704,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.5052,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.471416,-99) , 
11, 0.117894, 0, 0, 0.496815,-99) , 
1, 2813.5, 0, 0, 0.499114,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.443101,-99) , 
3, -3.0217, 0, 0, 0.496068,-99)    );
  // itree = 47
  fBoostWeights.push_back(0.0626799);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.53955,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.572606,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.481196,-99) , 
1, 1355.86, 1, 0, 0.530675,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.542392,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.479168,-99) , 
3, 2.94371, 0, 0, 0.483961,-99) , 
8, 0.991015, 0, 0, 0.489033,-99) , 
6, 12.7222, 1, 0, 0.492073,-99)    );
  // itree = 48
  fBoostWeights.push_back(0.0755181);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.608564,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.533447,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.479191,-99) , 
9, 2.72908, 0, 0, 0.501396,-99) , 
10, 210.888, 1, 0, 0.512376,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.603264,-99) , 
NN(
0, 
0, 
-1, 2.99227, 1, -1, 0.478867,-99) , 
1, 2052.02, 0, 0, 0.488247,-99) , 
2, 107.139, 0, 0, 0.502143,-99)    );
  // itree = 49
  fBoostWeights.push_back(0.0484644);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.55233,-99) , 
NN(
NN(
0, 
0, 
-1, 184.381, 1, 1, 0.513522,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.436469,-99) , 
8, 0.178398, 0, 0, 0.506679,-99) , 
8, 0.0891927, 1, 0, 0.509627,-99)    );
   return;
};
 
// Clean up
inline void ReadBDT_VBF0LowVPtHighMJJ::Clear() 
{
   for (unsigned int itree=0; itree<fForest.size(); itree++) { 
      delete fForest[itree]; 
   }
}
   inline double ReadBDT_VBF0LowVPtHighMJJ::GetMvaValue( const std::vector<double>& inputValues ) const
   {
      // classifier response value
      double retval = 0;

      // classifier response, sanity check first
      if (!IsStatusClean()) {
         std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                   << " because status is dirty" << std::endl;
         retval = 0;
      }
      else {
         if (IsNormalised()) {
            // normalise variables
            std::vector<double> iV;
            iV.reserve(inputValues.size());
            int ivar = 0;
            for (std::vector<double>::const_iterator varIt = inputValues.begin();
                 varIt != inputValues.end(); varIt++, ivar++) {
               iV.push_back(NormVariable( *varIt, fVmin[ivar], fVmax[ivar] ));
            }
            retval = GetMvaValue__( iV );
         }
         else {
            retval = GetMvaValue__( inputValues );
         }
      }

      return retval;
   }
